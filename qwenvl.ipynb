{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082c7f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过uv安装依赖\n",
    "! uv sync"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c34b805",
   "metadata": {},
   "source": [
    "# 下载Qwen/Qwen2.5-VL-3B-Instruct模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a28b3f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: ./autodl-tmp/qwen/Qwen2.5-VL-3B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 15:59:53,131 - modelscope - INFO - Target directory already exists, skipping creation.\n"
     ]
    }
   ],
   "source": [
    "from modelscope import snapshot_download\n",
    "from qwen_vl_utils import process_vision_info\n",
    "model_dir = snapshot_download('qwen/Qwen2.5-VL-3B-Instruct', cache_dir='./autodl-tmp', revision='master')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5fbbe4",
   "metadata": {},
   "source": [
    "# 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c3f576a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n",
      "You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58dcaef5f28544c9a4d2e03b4e746d24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,TrainingArguments, Trainer, DataCollatorForSeq2Seq, Qwen2_5_VLForConditionalGeneration, AutoProcessor\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./autodl-tmp/qwen/Qwen2.5-VL-3B-Instruct/\", use_fast=False, trust_remote_code=True)\n",
    "processor = AutoProcessor.from_pretrained(\"./autodl-tmp/qwen/Qwen2.5-VL-3B-Instruct/\")\n",
    "# 特别的，Qwen2-VL-2B-Instruct模型需要使用Qwen2VLForConditionalGeneration来加载\n",
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\"./autodl-tmp/qwen/Qwen2.5-VL-3B-Instruct/\", device_map=\"auto\", torch_dtype=torch.bfloat16, trust_remote_code=True,)\n",
    "model.enable_input_require_grads()  # 开启梯度检查点时，要执行该方法\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c619696a",
   "metadata": {},
   "source": [
    "# 集成swanlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dbbc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from swanlab.integration.transformers import SwanLabCallback\n",
    "from transformers import Trainer\n",
    "# 设置SwanLab回调\n",
    "swanlab_callback = SwanLabCallback(\n",
    "    project=\"Qwen2.5-VL-3B-finetune\",\n",
    "    experiment_name=\"Qwen2.5-VL-3B-finetune\",\n",
    "    config={\n",
    "        \"model\": \"https://modelscope.cn/models/Qwen/Qwen2-VL-2B-Instruct\",\n",
    "        # \"dataset\": \"https://modelscope.cn/datasets/modelscope/coco_2014_caption/quickstart\",\n",
    "        # \"github\": \"https://github.com/datawhalechina/self-llm\",\n",
    "        \"prompt\": \"COCO Yes: \",\n",
    "        \"train_data_number\": len(train_data),\n",
    "        \"lora_rank\": 64,\n",
    "        \"lora_alpha\": 16,\n",
    "        \"lora_dropout\": 0.1,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b41255",
   "metadata": {},
   "source": [
    "# 配置LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd609890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/www/qwenvl/.venv/lib/python3.13/site-packages/torch/cuda/__init__.py:182: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, TaskType, get_peft_model, PeftModel\n",
    "# 配置LoRA\n",
    "config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    inference_mode=False,  # 训练模式\n",
    "    r=64,  # Lora 秩\n",
    "    lora_alpha=16,  # Lora alaph，具体作用参见 Lora 原理\n",
    "    lora_dropout=0.05,  # Dropout 比例\n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "# 获取LoRA模型\n",
    "peft_model = get_peft_model(model, config)\n",
    "\n",
    "# 配置训练参数\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./output/Qwen2-VL-2B\",\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    logging_steps=10,\n",
    "    logging_first_step=5,\n",
    "    num_train_epochs=2,\n",
    "    save_steps=100,\n",
    "    learning_rate=1e-4,\n",
    "    save_on_each_node=True,\n",
    "    gradient_checkpointing=True,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32541cf3",
   "metadata": {},
   "source": [
    "# 配置trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f17b3055",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 配置Trainer\u001b[39;00m\n\u001b[32m      2\u001b[39m trainer = Trainer(\n\u001b[32m      3\u001b[39m     model=peft_model,\n\u001b[32m      4\u001b[39m     args=args,\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     train_dataset=\u001b[43mtrain_dataset\u001b[49m,\n\u001b[32m      6\u001b[39m     data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m      7\u001b[39m     callbacks=[swanlab_callback],\n\u001b[32m      8\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# 配置Trainer\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),\n",
    "    callbacks=[swanlab_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d557e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwenvl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
